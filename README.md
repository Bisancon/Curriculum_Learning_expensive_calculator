
# Описание проекта

Этот проект направлен на исследование метода **Curriculum Learning** для улучшения обучения трансформеров на примере решения простых математических операций. Метод **Curriculum Learning** предполагает, что модель сначала обучается на простых примерах, а затем постепенно переходит к более сложным. Гипотеза заключается в том, что поэтапное обучение модели на примерах возрастающей сложности способствует более быстрой сходимости и улучшает итоговое качество, по сравнению с обучением, основанным на случайном порядке подачи данных. Это позволяет моделям быстрее освоить основные концепции, прежде чем столкнуться с более трудными задачами. В рамках эксперимента проводится два независимых этапа обучения. На первом этапе данные подаются в случайном порядке, что соответствует стандартному подходу. На втором этапе используется **Curriculum Learning**.

В рамках этого проекта используется **Transformer Decoder** для решения математических операций, таких как сложение, вычитание, умножение и деление. Процесс обучения при использовании **Curriculum Learning** состоит из двух фаз:
1. **Обучение на простых данных**: Операторы + и -.
2. **Обучение на сложных данных**: Операторы * и ^2.

Мы проверяем гипотезу, что **Curriculum Learning** улучшит сходимость и качество модели, сравнивая результаты, полученные с различными стратегиями сэмплирования данных. Предполагается, что обучение с использованием **Curriculum Learning** приведёт к улучшению как качества, так и скорости обучения.

# Цели проекта

- Исследовать влияние подхода **Curriculum Learning** на задачу математических вычислений.
- Реализовать модель на основе трансформера для решения простых и сложных математических операций.
- Создать кастомный токенизатор для чисел и операторов в математических выражениях.
- Провести эксперимент с различными стратегиями сэмплирования данных (сложные -> простые и рандомизированные данные).
- Оценить результаты обучения и сходимость модели.
# Реализация
## Генерация данных

```bash
python data_generator.py
```

Для генерации данных используется скрипт data_generator.py, который генерирует датасет:

Результаты генерации сохраняются файл: 

- curriculum_data.csv — содержит все сгенерированные данные с простыми и сложными операциями.


## Токенизатор
Токенизатор **CurriculumTokenizer** предназначен для преобразования текстовых выражений в последовательность токенов, которые могут быть использованы моделью для обучения. Он также предоставляет возможность декодировать последовательности токенов обратно в текстовые выражения. Функция **encode** токенизирует текстовое выражение, а **decode** преобразует токены в текст.

Основные токены: 
- `<PAD>`: токен для дополнения последовательностей до одинаковой длины. 
- `<SOS>`: токен начала последовательности. 
- `<EOS>`: токен конца последовательности. 
- `<UNK>`: токен для неизвестных символов. 
- Математические операторы: '+': 4, '-': 5, '*': 6, '^': 7, '=': 8. 
- Цифры: от 0 до 9, которым соответствуют токены от 10 до 19.

## Модель
Модель основана на **Transformer Decoder**. Входные данные представляют собой последовательности токенов, полученных из математических выражений, которые модель обрабатывает и предсказывает результаты операций.

Параметры модели: 
- **num_tokens**: количество уникальных токенов в словаре (включая операторы и цифры). 
- **n_embd**: размерность эмбеддингов для входных токенов. 
- **num_layers**: количество слоев декодера. 
- **num_heads**: количество голов в механизме внимания. 
- **num_classes**: количество классов, равное диапазону возможных результатов операций. 

Обучение модели происходит в два этапа:

- Обучение с **Random Sampling**: На этом этапе данные подаются в случайном порядке, что моделирует случайный порядок представления задач при обучении. Используется стандартный загрузчик данных и стандартный порядок обработки. 
- Обучение с **Curriculum Learning**: Данные подаются в измененном порядке, начиная с простых примеров и постепенно переходя к более сложным.


# Результаты эксперимента

![image](https://github.com/user-attachments/assets/b9f3e547-bd7d-4734-b8c8-1463092ca818)

На графиках представлены результаты эксперимента, которые показывают динамику **Loss** и **Accuracy** для обоих подходов к обучению

На первом графике видно, что потери на тренировочной выборке уменьшаются в обоих подходах по мере увеличения числа эпох. При этом обучение с использованием **Curriculum Learning** демонстрирует более быстрое снижение потерь на тренировочной выборке, начиная с низких значений уже на первых эпохах. **Val Loss** для метода **Curriculum Learning**, напротив, остаются значительно выше на протяжении всего эксперимента, что может указывать на недостаточную генерализацию модели. Для случайного сэмплирования валидационные потери ниже, но всё же демонстрируют тренд на их увеличение с течением времени.

Второй график показывает изменение точности на тренировочной и валидационной выборках. Точность на тренировочной выборке для метода **Curriculum Learning** быстро растёт и достигает порядка 80% к десятой эпохе, превосходя случайное сэмплирование, которое достигает лишь порядка 60%. Однако точность на валидационной выборке для **Curriculum Learning** остаётся низкой и колеблется около 30–35%, практически не изменяясь в течение эксперимента. Для случайного сэмплирования валидационная точность демонстрирует схожий уровень с **Curriculum Learning**, но с меньшими колебаниями.

# Выводы

Результаты эксперимента демонстрируют, что использование **Curriculum Learning** способствует более быстрому снижению функции потерь и повышению точности на тренировочной выборке, что подтверждает гипотезу о его эффективности в улучшении сходимости модели. Однако на валидационной выборке данный подход не приводит к улучшению качества обобщения, о чём свидетельствует низкая и практически неизменная точность, а также высокие потери. Это может происходить по ряду причин, таких как переобучение и недостаточная генерализация. Модель могла обучиться специфическим паттернам в данных, предоставленных в определённом порядке, что ухудшает её способность работать с примерами, которые не следуют этому порядку. 
Таким образом, **Curriculum Learning** подтвердил свою эффективность в ускорении обучения модели, однако с точки зрения качества предсказаний на валидационных данных его результаты пока недостаточны для того что бы говорит о пользе данного подхода.

# Запуск эксперимента

Cначала клонируйте репозиторий:
```bash
git clone https://github.com/yourusername/curriculum-learning-math-transformer.git
cd Curriculum_Learning_expensive_calculator
python3 -m venv venv
.\venv\Scripts\activate
pip install -r requirements.txt
```
Для запуска проетка достаточно запустить main.py
```bash
python main.py
```

Файл конфигурации: config.yaml
